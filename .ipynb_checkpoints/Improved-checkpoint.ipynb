{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21dfc85e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking GPU status...\n",
      "--------------------------------------------------\n",
      "✓ NVIDIA GPU detected\n",
      "  GPU: | NVIDIA-SMI 555.99                 Driver Version: 555.99         CUDA Version: 12.5     |\n",
      "✗ PyTorch not installed\n",
      "✓ XGBoost installed: 3.0.5\n",
      "  GPU support: Enabled\n",
      "✓ LightGBM installed: 4.6.0\n",
      "  GPU support: Disabled (CPU only)\n",
      "✓ CatBoost installed: 1.2.8\n",
      "  GPU support: Enabled\n",
      "--------------------------------------------------\n",
      "✗ GPU NOT AVAILABLE - Models will use CPU\n",
      "\n",
      "To enable GPU:\n",
      "1. Install CUDA: https://developer.nvidia.com/cuda-downloads\n",
      "2. Install GPU versions:\n",
      "   pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118\n",
      "   pip install xgboost --upgrade\n",
      "   pip install lightgbm --install-option=--gpu\n",
      "   pip install catboost\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def setup_gpu():\n",
    "    \"\"\"Check GPU availability and configure libraries\"\"\"\n",
    "    \n",
    "    print(\"Checking GPU status...\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Check NVIDIA GPU\n",
    "    try:\n",
    "        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True, timeout=5)\n",
    "        if result.returncode == 0:\n",
    "            print(\"✓ NVIDIA GPU detected\")\n",
    "            # Extract GPU name from nvidia-smi output\n",
    "            lines = result.stdout.split('\\n')\n",
    "            for line in lines:\n",
    "                if 'NVIDIA' in line or 'GeForce' in line or 'Tesla' in line or 'Quadro' in line:\n",
    "                    print(f\"  GPU: {line.strip()}\")\n",
    "                    break\n",
    "        else:\n",
    "            print(\"✗ NVIDIA driver not found\")\n",
    "            return False\n",
    "    except FileNotFoundError:\n",
    "        print(\"✗ nvidia-smi not found - No NVIDIA GPU\")\n",
    "        return False\n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(\"✗ nvidia-smi timeout\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"✗ GPU check failed: {e}\")\n",
    "        return False\n",
    "    \n",
    "    # Check PyTorch CUDA\n",
    "    try:\n",
    "        import torch\n",
    "        cuda_available = torch.cuda.is_available()\n",
    "        print(f\"✓ PyTorch installed: {torch.__version__}\")\n",
    "        print(f\"  CUDA available: {cuda_available}\")\n",
    "        if cuda_available:\n",
    "            print(f\"  CUDA version: {torch.version.cuda}\")\n",
    "            print(f\"  GPU name: {torch.cuda.get_device_name(0)}\")\n",
    "            print(f\"  GPU count: {torch.cuda.device_count()}\")\n",
    "    except ImportError:\n",
    "        print(\"✗ PyTorch not installed\")\n",
    "        cuda_available = False\n",
    "    except Exception as e:\n",
    "        print(f\"⚠ PyTorch check failed: {e}\")\n",
    "        cuda_available = False\n",
    "    \n",
    "    # Check XGBoost GPU\n",
    "    try:\n",
    "        import xgboost as xgb\n",
    "        xgb_version = xgb.__version__\n",
    "        print(f\"✓ XGBoost installed: {xgb_version}\")\n",
    "        # Test GPU training\n",
    "        try:\n",
    "            test_param = {'tree_method': 'gpu_hist', 'verbosity': 0}\n",
    "            test_dm = xgb.DMatrix(data=[[1,2],[3,4]], label=[1,0])\n",
    "            xgb.train(test_param, test_dm, num_boost_round=1)\n",
    "            print(\"  GPU support: Enabled\")\n",
    "        except:\n",
    "            print(\"  GPU support: Disabled (CPU only)\")\n",
    "    except ImportError:\n",
    "        print(\"✗ XGBoost not installed\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠ XGBoost check failed: {e}\")\n",
    "    \n",
    "    # Check LightGBM GPU\n",
    "    try:\n",
    "        import lightgbm as lgb\n",
    "        lgb_version = lgb.__version__\n",
    "        print(f\"✓ LightGBM installed: {lgb_version}\")\n",
    "        # Check if GPU version\n",
    "        try:\n",
    "            test_data = lgb.Dataset([[1,2],[3,4]], label=[1,0])\n",
    "            test_params = {'device': 'gpu', 'verbosity': -1}\n",
    "            lgb.train(test_params, test_data, num_boost_round=1)\n",
    "            print(\"  GPU support: Enabled\")\n",
    "        except:\n",
    "            print(\"  GPU support: Disabled (CPU only)\")\n",
    "    except ImportError:\n",
    "        print(\"✗ LightGBM not installed\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠ LightGBM check failed: {e}\")\n",
    "    \n",
    "    # Check CatBoost GPU\n",
    "    try:\n",
    "        from catboost import CatBoostRegressor\n",
    "        import catboost as cb\n",
    "        print(f\"✓ CatBoost installed: {cb.__version__}\")\n",
    "        # Test GPU\n",
    "        try:\n",
    "            test_model = CatBoostRegressor(iterations=1, task_type='GPU', verbose=0)\n",
    "            test_model.fit([[1,2],[3,4]], [1,0])\n",
    "            print(\"  GPU support: Enabled\")\n",
    "        except:\n",
    "            print(\"  GPU support: Disabled (CPU only)\")\n",
    "    except ImportError:\n",
    "        print(\"✗ CatBoost not installed\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠ CatBoost check failed: {e}\")\n",
    "    \n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Final verdict\n",
    "    if cuda_available:\n",
    "        print(\"✓ GPU READY - Models will use GPU acceleration\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"✗ GPU NOT AVAILABLE - Models will use CPU\")\n",
    "        print(\"\\nTo enable GPU:\")\n",
    "        print(\"1. Install CUDA: https://developer.nvidia.com/cuda-downloads\")\n",
    "        print(\"2. Install GPU versions:\")\n",
    "        print(\"   pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118\")\n",
    "        print(\"   pip install xgboost --upgrade\")\n",
    "        print(\"   pip install lightgbm --install-option=--gpu\")\n",
    "        print(\"   pip install catboost\")\n",
    "        return False\n",
    "\n",
    "# Run GPU check\n",
    "gpu_available = setup_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33f1be86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "# Run this in Jupyter cell:\n",
    "!pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72c8089",
   "metadata": {},
   "source": [
    "# Improved code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "416cdf77",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Amazon ML Challenge - Text-Only Optimized\n",
      "Target: 48-52% SMAPE | Runtime: ~18 minutes with GPU\n",
      "======================================================================\n",
      "\n",
      "Loading data...\n",
      "   Train: 75,000 samples\n",
      "   Test:  75,000 samples\n",
      "\n",
      "Validating data...\n",
      "   Complete\n",
      "\n",
      "======================================================================\n",
      "FEATURE EXTRACTION\n",
      "======================================================================\n",
      "\n",
      "Extracting text features...\n",
      "   28 features (79.6s)\n",
      "\n",
      "TF-IDF vectorization...\n",
      "   120 features (91.7s)\n",
      "\n",
      "Combining features...\n",
      "   Total features: 148\n",
      "\n",
      "======================================================================\n",
      "MODEL TRAINING (5-FOLD CV)\n",
      "======================================================================\n",
      "\n",
      "GPU Status:\n",
      "  XGBoost: GPU\n",
      "  CatBoost: GPU\n",
      "  LightGBM: CPU (GPU not compiled)\n",
      "\n",
      "Fold 1/5\n",
      "   LightGBM    58.96%\n",
      "   XGBoost     56.24%\n",
      "   CatBoost    58.42%\n",
      "   Ensemble    57.53%\n",
      "\n",
      "Fold 2/5\n",
      "   LightGBM    57.96%\n",
      "   XGBoost     55.73%\n",
      "   CatBoost    57.33%\n",
      "   Ensemble    56.64%\n",
      "\n",
      "Fold 3/5\n",
      "   LightGBM    58.55%\n",
      "   XGBoost     56.01%\n",
      "   CatBoost    58.00%\n",
      "   Ensemble    57.18%\n",
      "\n",
      "Fold 4/5\n",
      "   LightGBM    57.27%\n",
      "   XGBoost     55.01%\n",
      "   CatBoost    56.77%\n",
      "   Ensemble    55.96%\n",
      "\n",
      "Fold 5/5\n",
      "   LightGBM    58.60%\n",
      "   XGBoost     55.89%\n",
      "   CatBoost    57.82%\n",
      "   Ensemble    57.09%\n",
      "\n",
      "======================================================================\n",
      "FINAL RESULTS\n",
      "======================================================================\n",
      "Cross-Validation SMAPE: 56.88%\n",
      "Fold Scores: ['57.53%', '56.64%', '57.18%', '55.96%', '57.09%']\n",
      "Std Dev: 0.54%\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "SUBMISSION SAVED\n",
      "======================================================================\n",
      "   File: test_out.csv\n",
      "   Rows: 75,000\n",
      "   Price range: $1.48 - $175.81\n",
      "   Expected SMAPE: ~56.88%\n",
      "\n",
      "Upload test_out.csv to the leaderboard!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Amazon ML Challenge - Text-Only Optimized Solution\n",
    "Target SMAPE: 48-52% | Runtime: ~18 minutes with GPU\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# GPU detection\n",
    "try:\n",
    "    import subprocess\n",
    "    result = subprocess.run(['nvidia-smi'], capture_output=True, timeout=2)\n",
    "    gpu_available = result.returncode == 0\n",
    "except:\n",
    "    gpu_available = False\n",
    "\n",
    "def smape(y_true, y_pred):\n",
    "    \"\"\"Calculate SMAPE metric\"\"\"\n",
    "    return 100 * np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred)))\n",
    "\n",
    "def extract_text_features(df):\n",
    "    \"\"\"Extract statistical features from text content\"\"\"\n",
    "    \n",
    "    df['catalog_content'] = df['catalog_content'].fillna('').astype(str)\n",
    "    \n",
    "    features = pd.DataFrame()\n",
    "    \n",
    "    # Basic text statistics\n",
    "    features['text_len'] = df['catalog_content'].str.len()\n",
    "    features['word_count'] = df['catalog_content'].str.split().str.len()\n",
    "    features['unique_words'] = df['catalog_content'].apply(lambda x: len(set(str(x).lower().split())))\n",
    "    features['avg_word_len'] = features['text_len'] / (features['word_count'] + 1)\n",
    "    \n",
    "    # Character patterns\n",
    "    features['digit_count'] = df['catalog_content'].str.count(r'\\d')\n",
    "    features['upper_count'] = df['catalog_content'].str.count(r'[A-Z]')\n",
    "    features['special_char_count'] = df['catalog_content'].str.count(r'[^a-zA-Z0-9\\s]')\n",
    "    features['space_count'] = df['catalog_content'].str.count(r'\\s')\n",
    "    \n",
    "    # Numeric features\n",
    "    features['has_numbers'] = (features['digit_count'] > 0).astype(int)\n",
    "    features['digit_ratio'] = features['digit_count'] / (features['text_len'] + 1)\n",
    "    \n",
    "    # Text complexity\n",
    "    features['lexical_diversity'] = features['unique_words'] / (features['word_count'] + 1)\n",
    "    features['uppercase_ratio'] = features['upper_count'] / (features['text_len'] + 1)\n",
    "    \n",
    "    # Price-related patterns\n",
    "    features['has_currency'] = df['catalog_content'].str.contains(r'[\\$£€¥₹]', regex=True).astype(int)\n",
    "    features['has_percentage'] = df['catalog_content'].str.contains(r'%', regex=False).astype(int)\n",
    "    features['has_measurement'] = df['catalog_content'].str.contains(r'\\d+\\s*(kg|g|ml|l|cm|m|inch|oz|lb)', \n",
    "                                                                      regex=True, case=False).astype(int)\n",
    "    \n",
    "    # Common keywords\n",
    "    features['has_pack'] = df['catalog_content'].str.contains('pack', case=False).astype(int)\n",
    "    features['has_set'] = df['catalog_content'].str.contains('set', case=False).astype(int)\n",
    "    features['has_piece'] = df['catalog_content'].str.contains('piece|pcs', case=False).astype(int)\n",
    "    \n",
    "    # Punctuation\n",
    "    features['comma_count'] = df['catalog_content'].str.count(',')\n",
    "    features['dot_count'] = df['catalog_content'].str.count(r'\\.')\n",
    "    features['exclamation_count'] = df['catalog_content'].str.count('!')\n",
    "    \n",
    "    # Extract numbers from text\n",
    "    def extract_numbers(text):\n",
    "        numbers = re.findall(r'\\d+\\.?\\d*', str(text))\n",
    "        if numbers:\n",
    "            nums = [float(n) for n in numbers]\n",
    "            return np.mean(nums), np.max(nums), len(nums)\n",
    "        return 0, 0, 0\n",
    "    \n",
    "    number_stats = df['catalog_content'].apply(extract_numbers)\n",
    "    features['avg_number'] = [x[0] for x in number_stats]\n",
    "    features['max_number'] = [x[1] for x in number_stats]\n",
    "    features['number_count'] = [x[2] for x in number_stats]\n",
    "    \n",
    "    # Word statistics\n",
    "    features['short_word_count'] = df['catalog_content'].apply(\n",
    "        lambda x: len([w for w in str(x).split() if len(w) <= 3])\n",
    "    )\n",
    "    features['long_word_count'] = df['catalog_content'].apply(\n",
    "        lambda x: len([w for w in str(x).split() if len(w) >= 10])\n",
    "    )\n",
    "    \n",
    "    # Sentence statistics\n",
    "    features['sentence_count'] = df['catalog_content'].str.count(r'[.!?]') + 1\n",
    "    features['avg_sentence_len'] = features['word_count'] / features['sentence_count']\n",
    "    \n",
    "    return features.fillna(0)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"Amazon ML Challenge - Text-Only Optimized\")\n",
    "print(\"Target: 48-52% SMAPE | Runtime: ~18 minutes with GPU\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "# Load data\n",
    "print(\"Loading data...\")\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "print(f\"   Train: {len(train_df):,} samples\")\n",
    "print(f\"   Test:  {len(test_df):,} samples\")\n",
    "print()\n",
    "\n",
    "# Validate data\n",
    "print(\"Validating data...\")\n",
    "assert 'catalog_content' in train_df.columns, \"Missing catalog_content\"\n",
    "assert 'price' in train_df.columns, \"Missing price\"\n",
    "train_df = train_df.dropna(subset=['price'])\n",
    "print(\"   Complete\")\n",
    "print()\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"FEATURE EXTRACTION\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "# Extract text features\n",
    "print(\"Extracting text features...\")\n",
    "import time\n",
    "t0 = time.time()\n",
    "train_text = extract_text_features(train_df)\n",
    "test_text = extract_text_features(test_df)\n",
    "print(f\"   {train_text.shape[1]} features ({time.time()-t0:.1f}s)\")\n",
    "print()\n",
    "\n",
    "# TF-IDF features\n",
    "print(\"TF-IDF vectorization...\")\n",
    "t0 = time.time()\n",
    "train_df['catalog_content'] = train_df['catalog_content'].fillna('').astype(str)\n",
    "test_df['catalog_content'] = test_df['catalog_content'].fillna('').astype(str)\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=120,\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=3,\n",
    "    max_df=0.9,\n",
    "    sublinear_tf=True\n",
    ")\n",
    "train_tfidf = tfidf.fit_transform(train_df['catalog_content'])\n",
    "test_tfidf = tfidf.transform(test_df['catalog_content'])\n",
    "\n",
    "train_tfidf_df = pd.DataFrame(\n",
    "    train_tfidf.toarray(), \n",
    "    columns=[f'tfidf_{i}' for i in range(train_tfidf.shape[1])]\n",
    ")\n",
    "test_tfidf_df = pd.DataFrame(\n",
    "    test_tfidf.toarray(), \n",
    "    columns=[f'tfidf_{i}' for i in range(test_tfidf.shape[1])]\n",
    ")\n",
    "print(f\"   {train_tfidf_df.shape[1]} features ({time.time()-t0:.1f}s)\")\n",
    "print()\n",
    "\n",
    "# Combine features\n",
    "print(\"Combining features...\")\n",
    "X_train = pd.concat([train_text, train_tfidf_df], axis=1).reset_index(drop=True)\n",
    "X_test = pd.concat([test_text, test_tfidf_df], axis=1).reset_index(drop=True)\n",
    "y_train = np.log1p(train_df['price'].values)\n",
    "\n",
    "print(f\"   Total features: {X_train.shape[1]}\")\n",
    "print()\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"MODEL TRAINING (5-FOLD CV)\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "print(\"GPU Status:\")\n",
    "print(f\"  XGBoost: {'GPU' if gpu_available else 'CPU'}\")\n",
    "print(f\"  CatBoost: {'GPU' if gpu_available else 'CPU'}\")\n",
    "print(f\"  LightGBM: CPU (GPU not compiled)\")\n",
    "print()\n",
    "\n",
    "# Cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "fold_scores = []\n",
    "test_preds_lgb = np.zeros(len(X_test))\n",
    "test_preds_xgb = np.zeros(len(X_test))\n",
    "test_preds_cat = np.zeros(len(X_test))\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train), 1):\n",
    "    print(f\"Fold {fold}/5\")\n",
    "    \n",
    "    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "    y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
    "    \n",
    "    # LightGBM\n",
    "    lgb_params = {\n",
    "        'n_estimators': 500,\n",
    "        'learning_rate': 0.05,\n",
    "        'max_depth': 10,\n",
    "        'num_leaves': 31,\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'random_state': 42,\n",
    "        'n_jobs': -1,\n",
    "        'verbose': -1\n",
    "    }\n",
    "    lgb_model = lgb.LGBMRegressor(**lgb_params)\n",
    "    lgb_model.fit(\n",
    "        X_tr, y_tr, \n",
    "        eval_set=[(X_val, y_val)],\n",
    "        callbacks=[lgb.early_stopping(50, verbose=False)]\n",
    "    )\n",
    "    lgb_pred = lgb_model.predict(X_val)\n",
    "    lgb_score = smape(np.expm1(y_val), np.expm1(lgb_pred))\n",
    "    test_preds_lgb += lgb_model.predict(X_test) / 5\n",
    "    print(f\"   LightGBM    {lgb_score:.2f}%\")\n",
    "    \n",
    "    # XGBoost\n",
    "    xgb_params = {\n",
    "        'n_estimators': 500,\n",
    "        'learning_rate': 0.05,\n",
    "        'max_depth': 10,\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'tree_method': 'gpu_hist' if gpu_available else 'hist',\n",
    "        'predictor': 'gpu_predictor' if gpu_available else 'auto',\n",
    "        'early_stopping_rounds': 50,\n",
    "        'random_state': 42,\n",
    "        'n_jobs': -1,\n",
    "        'verbosity': 0\n",
    "    }\n",
    "    xgb_model = xgb.XGBRegressor(**xgb_params)\n",
    "    xgb_model.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], verbose=False)\n",
    "    xgb_pred = xgb_model.predict(X_val)\n",
    "    xgb_score = smape(np.expm1(y_val), np.expm1(xgb_pred))\n",
    "    test_preds_xgb += xgb_model.predict(X_test) / 5\n",
    "    print(f\"   XGBoost     {xgb_score:.2f}%\")\n",
    "    \n",
    "    # CatBoost\n",
    "    cat_params = {\n",
    "        'iterations': 500,\n",
    "        'learning_rate': 0.05,\n",
    "        'depth': 10,\n",
    "        'task_type': 'GPU' if gpu_available else 'CPU',\n",
    "        'random_state': 42,\n",
    "        'verbose': 0,\n",
    "        'early_stopping_rounds': 50\n",
    "    }\n",
    "    cat_model = CatBoostRegressor(**cat_params)\n",
    "    cat_model.fit(X_tr, y_tr, eval_set=(X_val, y_val), verbose=False)\n",
    "    cat_pred = cat_model.predict(X_val)\n",
    "    cat_score = smape(np.expm1(y_val), np.expm1(cat_pred))\n",
    "    test_preds_cat += cat_model.predict(X_test) / 5\n",
    "    print(f\"   CatBoost    {cat_score:.2f}%\")\n",
    "    \n",
    "    # Ensemble\n",
    "    ensemble_pred = (lgb_pred + xgb_pred + cat_pred) / 3\n",
    "    ensemble_score = smape(np.expm1(y_val), np.expm1(ensemble_pred))\n",
    "    fold_scores.append(ensemble_score)\n",
    "    print(f\"   Ensemble    {ensemble_score:.2f}%\")\n",
    "    print()\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"FINAL RESULTS\")\n",
    "print(\"=\" * 70)\n",
    "cv_score = np.mean(fold_scores)\n",
    "print(f\"Cross-Validation SMAPE: {cv_score:.2f}%\")\n",
    "print(f\"Fold Scores: {[f'{s:.2f}%' for s in fold_scores]}\")\n",
    "print(f\"Std Dev: {np.std(fold_scores):.2f}%\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "# Generate submission\n",
    "final_preds = (test_preds_lgb + test_preds_xgb + test_preds_cat) / 3\n",
    "final_preds = np.expm1(final_preds)\n",
    "\n",
    "# Use sample_id from test data (required by competition)\n",
    "submission = pd.DataFrame({\n",
    "    'sample_id': test_df['sample_id'],\n",
    "    'price': final_preds\n",
    "})\n",
    "submission.to_csv('test_out.csv', index=False)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"SUBMISSION SAVED\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"   File: test_out.csv\")\n",
    "print(f\"   Rows: {len(submission):,}\")\n",
    "print(f\"   Price range: ${submission['price'].min():.2f} - ${submission['price'].max():.2f}\")\n",
    "print(f\"   Expected SMAPE: ~{cv_score:.2f}%\")\n",
    "print()\n",
    "print(\"Upload test_out.csv to the leaderboard!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78790e71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
